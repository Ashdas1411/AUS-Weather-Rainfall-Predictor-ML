# ğŸŒ¦ï¸ Australian Weather Rainfall Predictor (Melbourne Region)

This project builds a **machine learning pipeline** to predict whether it will rain **today** in the Melbourne region using historical Australian weather data.  
The focus is not just on accuracy, but on understanding **seasonality**, **geographic effects**, and **class imbalance** in real-world weather prediction.

---

## ğŸ¯ Problem Statement

Rainfall prediction is a classic classification problem with:
- Strong **seasonal patterns** ğŸŒ¤ï¸â„ï¸
- Significant **geographic variation** ğŸ“
- Severe **class imbalance** âš–ï¸

In Melbourne, rain occurs far less frequently than dry days.  
A naÃ¯ve model that always predicts *â€œNo Rainâ€* would already be correct about **76% of the time** â€” without learning anything meaningful.

This project explores how to go beyond that illusion of accuracy.

---

## ğŸ“Š Dataset

- **Source:** Australian weather dataset  
- **Original size:** ~145,000 records  
- **Target variable:** `RainToday` (Yes / No)

### ğŸ§¹ Data Cleaning & Selection
- Dropped rows with missing values due to heavy sparsity in sunshine and cloud features
- Focused on **Melbourne**, **Melbourne Airport**, and **Watsonia** to reduce geographic noise
- Renamed target variables for clarity (`RainYesterday`, `RainToday`)

### ğŸ“¦ Final Dataset
- **7,557 observations**
- **16 numerical features**
- **7 categorical features**

---

## ğŸ› ï¸ Feature Engineering

- ğŸŒ¦ï¸ **Season extraction** from date (Summer, Autumn, Winter, Spring)
- ğŸ”¢ **Standard scaling** for numerical features
- ğŸ”  **One-hot encoding** for categorical variables
- ğŸ“ Location retained as a categorical feature to capture local weather patterns

---

## âš–ï¸ Class Imbalance Insight

Only **~24%** of observations correspond to rainy days â˜”.  
This imbalance can easily trick models into favoring dry-day predictions.

To address this:
- Stratified train-test splitting was used
- Evaluation focused on **precision, recall, F1-score**, not just accuracy
- Confusion matrices were analyzed to inspect model behavior

---

## ğŸ¤– Models Used

### ğŸŒ² Random Forest Classifier
- Hyperparameter tuning via **GridSearchCV**
- 5-fold **StratifiedKFold** cross-validation

**Best parameters:**
- `n_estimators = 100`
- `max_depth = 20`
- `min_samples_split = 2`

**Performance:**
- âœ… Cross-validation accuracy: **~85%**
- âœ… Test accuracy: **~84%**
- âš ï¸ Recall for rainy days: **~51%**

ğŸ” Feature importance analysis highlighted:
- Humidity
- Pressure
- Cloud cover
- Rainfall
- Seasonal effects

---

### ğŸ“ Logistic Regression (Baseline Comparison)

- Tested with L1 and L2 regularization
- Evaluated with and without class weighting

**Performance:**
- Slightly lower accuracy (**~83%**)
- Similar recall for rainy days
- Useful as a baseline and for interpretability

---

## ğŸ“ˆ Evaluation Metrics

- ğŸ“„ Classification Report (Precision, Recall, F1-score)
- ğŸ§© Confusion Matrix visualizations
- ğŸ“Š Feature importance plots (Random Forest)

These metrics provide a more realistic picture than accuracy alone.

---

## ğŸ§  Key Takeaways

- ğŸ“ Localized models outperform global ones
- âš–ï¸ Class imbalance must be handled carefully
- ğŸŒ² Random Forest performed better than Logistic Regression
- â˜” Predicting rainy days remains the hardest challenge

---

## ğŸ§° Tools & Libraries

- ğŸ Python
- ğŸ¼ Pandas
- ğŸ”¢ NumPy
- ğŸ¤– Scikit-learn
- ğŸ“Š Matplotlib
- ğŸ¨ Seaborn

---

## ğŸš€ Future Improvements

- Apply resampling techniques (SMOTE, undersampling)
- Optimize models for **recall** or **F1-score**
- Extend the approach to other Australian regions
- Incorporate time-based and rolling weather features

---

## ğŸ“Œ Status

âœ… Baseline model completed  
ğŸ”§ Further experimentation and improvements planned
